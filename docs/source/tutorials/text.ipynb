{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with TensorFlow, Keras, and Cleanlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this 5-minute quickstart tutorial, we use cleanlab to find potential label errors in a text classification dataset of [IMDB movie reviews](https://ai.stanford.edu/~amaas/data/sentiment/). This dataset contains 50,000 text reviews, each labeled with a binary sentiment polarity label indicating whether the review is positive (1) or negative (0). cleanlab will shortlist _hundreds_ of examples that confuse our ML model the most; many of which are potential label errors, edge cases, or otherwise ambiguous examples.\n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Build a simple TensorFlow & Keras neural network and wrap it with cleanlab's `KerasWrapperSequential`.  This wrapper class  makes *any* Keras/Tensorflow model compatible with scikit-learn (and some advanced cleanlab functionality like `CleanLearning` is easier to run with scikit-learn-compatible models).\n",
    "\n",
    "- Use `CleanLearning` to automatically compute out-of-sample preddicted probabilites and identify potential label errors with the `find_label_issues` method.\n",
    "\n",
    "- Train a more robust version of the same neural network after dropping the identified label errors using `CleanLearning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Quickstart\n",
    "<br/>\n",
    "    \n",
    "Already have an sklearn compatible `model`, `data` and given `labels`? Run the code below to train your `model` and get label issues using `CleanLearning`. \n",
    "    \n",
    "You can subsequently use the same `CleanLearning` object to train a more robust model (only trained on the clean data) by calling the `.fit()` method and passing in the `label_issues` found earlier.\n",
    "\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.classification import CleanLearning\n",
    "\n",
    "cl = CleanLearning(model)\n",
    "label_issues = cl.find_label_issues(train_data, labels)  # identify mislabeled examples \n",
    "  \n",
    "cl.fit(train_data, labels, label_issues=label_issues)\n",
    "preds = cl.predict(test_data)  # predictions from a version of your model \n",
    "                               # trained on auto-cleaned data\n",
    "\n",
    "\n",
    "```\n",
    "    \n",
    "</div>\n",
    "    \n",
    "Is your model/data not compatible with `CleanLearning`? You can instead run cross-validation on your model to get out-of-sample `pred_probs`. Then run the code below to get label issue indices ranked by their inferred severity.\n",
    "\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "ranked_label_issues = find_label_issues(\n",
    "    labels,\n",
    "    pred_probs,\n",
    "    return_indices_ranked_by=\"self_confidence\",\n",
    ")\n",
    "    \n",
    "\n",
    "```\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install required dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install sklearn tensorflow tensorflow-datasets\n",
    "!pip install cleanlab\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs.cleanlab.ai).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "# Package versions we used: tensorflow==2.9.1 scikit-learn==1.2.0 tensorflow_datasets==4.5.2\n",
    "\n",
    "dependencies = [\"cleanlab\", \"sklearn\", \"tensorflow\", \"tensorflow_datasets\"]\n",
    "\n",
    "# Supress outputs that may appear if tensorflow happens to be improperly installed: \n",
    "import os \n",
    "import logging \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # suppress tensorflow log output \n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL) \n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab  # for colab\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string \n",
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score, log_loss \n",
    "from sklearn.model_selection import cross_val_predict \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers \n",
    "import tensorflow_datasets as tfds \n",
    "\n",
    "from cleanlab.classification import CleanLearning\n",
    "from cleanlab.models.keras import KerasWrapperSequential\n",
    "\n",
    "SEED = 123456  # for reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# This cell is hidden from docs.cleanlab.ai \n",
    "\n",
    "import random \n",
    "import numpy as np \n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None) \n",
    "\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and preprocess the IMDb text dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is provided in TensorFlow's Datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "raw_train_ds = tfds.load(name=\"imdb_reviews\", split=\"train\", batch_size=-1, as_supervised=True)\n",
    "raw_test_ds = tfds.load(name=\"imdb_reviews\", split=\"test\", batch_size=-1, as_supervised=True)\n",
    "\n",
    "raw_train_texts, train_labels = tfds.as_numpy(raw_train_ds)\n",
    "raw_test_texts, test_labels = tfds.as_numpy(raw_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(train_labels))\n",
    "print(f\"Classes: {set(train_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first example in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(f\"Example Label: {train_labels[i]}\")\n",
    "print(f\"Example Text: {raw_train_texts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored as two numpy arrays for each the train and test set:\n",
    "\n",
    "1. `raw_train_texts` and `raw_test_texts` for the movie reviews in text format,\n",
    "2. `train_labels` and `test_labels` for the labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Bringing Your Own Data (BYOD)?\n",
    "\n",
    "You can easily replace the above with your own text dataset, and continue with the rest of the tutorial.\n",
    "\n",
    "Your classes (and entries of `train_labels` / `test_labels`) should be represented as integer indices 0, 1, ..., num_classes - 1.\n",
    "For example, if your dataset has 7 examples from 3 classes, `train_labels` might be: `np.array([2,0,0,1,2,0,1])`\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to convert the text strings into vectors which are better suited as inputs for neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to define a function to preprocess the text data by:\n",
    "\n",
    "1. Converting it to lower case\n",
    "2. Removing the HTML break tags: `<br />`\n",
    "3. Removing any punctuation marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use a `TextVectorization` layer to preprocess, tokenize, and vectorize our text data to a suitabable format for a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=preprocess_text,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting `vectorize_layer` to the text data creates a mapping of each token (i.e. word) to an integer index. Note that we only adapt the vectorization on the train set, as it is standard ML practice. \n",
    "\n",
    "Subsequently, we can vectorize our text data in the train and test sets by using this mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.reset_state()\n",
    "vectorize_layer.adapt(raw_train_texts)\n",
    "\n",
    "train_texts = vectorize_layer(raw_train_texts).numpy()\n",
    "test_texts = vectorize_layer(raw_test_texts).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our subsequent neural network models will directly operate on elements of `train_texts` and `test_texts` in order to classify reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a classification model and use cleanlab to find potential label errors\n",
    "\n",
    "<a id=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we build a simple neural network for classification with TensorFlow and Keras. We will also wrap it with cleanlab's `KerasWrapperSequential` to make it compatible with sklearn (and hence`CleanLearning`). Note: you can wrap *any* existing Keras model this way, by just replacing `keras.Sequential` with `KerasWrapperSequential` in your code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model():\n",
    "    # simply replace `keras.Sequential(` with cleanlab's class in this line to make any keras model sklearn-compatible \n",
    "    # the rest of your existing keras code does not need to change at all \n",
    "    model = KerasWrapperSequential(  \n",
    "        [  \n",
    "            tf.keras.Input(shape=(None,), dtype=\"int64\"),\n",
    "            layers.Embedding(max_features + 1, 16),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(num_classes),\n",
    "            layers.Softmax()\n",
    "        ],  # outputs probability that text belongs to class 1\n",
    "        compile_kwargs= {\n",
    "          \"optimizer\":\"adam\",\n",
    "          \"loss\":tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "          \"metrics\":tf.keras.metrics.CategoricalAccuracy(),\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the `CleanLearning` object with the neural network model and use `find_label_issues` to identify potential label errors.\n",
    "\n",
    "`CleanLearning` provides a wrapper class that can easily be applied to any scikit-learn compatible model, which can be used to find potential label issues and train a more robust model if the original data contains noisy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_n_folds = 3  # for efficiency; values like 5 or 10 will generally work better\n",
    "num_epochs = 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_nn_model()\n",
    "cl = CleanLearning(model, cv_n_folds=cv_n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_issues = cl.find_label_issues(X=train_texts, labels=train_labels, clf_kwargs={\"epochs\": num_epochs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_label_issues` method above will perform cross validation to compute out-of-sample predicted probabilites for each example, which is used to identify label issues.\n",
    "\n",
    "This method returns a dataframe containing a label quality score for each example. These numeric scores lie between 0 and 1, where  lower scores indicate examples more likely to be mislabeled. The dataframe also contains a boolean column specifying whether or not each example is identified to have a label issue (indicating it is likely mislabeled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the subset of examples flagged with label issues, and also sort by label quality score to find the indices of the 10 most likely mislabeled examples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_issues = label_issues[label_issues[\"is_label_issue\"] == True]\n",
    "lowest_quality_labels = label_issues[\"label_quality\"].argsort()[:10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"cleanlab found {len(identified_issues)} potential label errors in the dataset.\\n\"\n",
    "    f\"Here are indices of the top 10 most likely errors: \\n {lowest_quality_labels}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review some of the most likely label errors:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us inspect these datapoints, we define a method to print any example from the dataset. We then display some of the top-ranked label issues identified by `cleanlab`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_as_df(index):\n",
    "    return pd.DataFrame(\n",
    "        {\"texts\": raw_train_texts[index], \"labels\": train_labels[index]},\n",
    "        [index]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a review labeled as positive (1), but it should be negative (0).\n",
    "Some noteworthy snippets extracted from the review text:\n",
    "\n",
    "> - \"...incredibly **awful** score...\"\n",
    ">\n",
    "> - \"...**worst** Foley work ever done.\"\n",
    ">\n",
    "> - \"...script is **incomprehensible**...\"\n",
    ">\n",
    "> - \"...editing is just **bizarre**.\"\n",
    ">\n",
    "> - \"...**atrocious** pan and scan...\"\n",
    ">\n",
    "> - \"...**incoherent mess**...\"\n",
    ">\n",
    "> - \"...**amateur** directing there.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_as_df(22294)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a review labeled as positive (1), but it should be negative (0).\n",
    "Some noteworthy snippets extracted from the review text:\n",
    "\n",
    "> - \"...film seems **cheap**.\"\n",
    ">\n",
    "> - \"...unbelievably **bad**...\"\n",
    ">\n",
    "> - \"...cinematography is **badly** lit...\"\n",
    ">\n",
    "> - \"...everything looking **grainy** and **ugly**.\"\n",
    ">\n",
    "> - \"...sound is so **terrible**...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_as_df(5204)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a review labeled as positive (1), but it should be negative (0).\n",
    "Some noteworthy snippets extracted from the review text:\n",
    "\n",
    "> - \"...hard to imagine a **boring** shark movie...\"\n",
    ">\n",
    "> - \"**Poor focus** in some scenes made the production seems **amateurish**.\"\n",
    ">\n",
    "> - \"...**do nothing** to take advantage of...\"\n",
    ">\n",
    "> - \"...**far too few** scenes of any depth or variety.\"\n",
    ">\n",
    "> - \"...just **look flat**...no contrast of depth...\"\n",
    ">\n",
    "> - \"...**introspective** and **dull**...constant **disappointment**.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_as_df(15079)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanlab has shortlisted the most likely label errors to speed up your data cleaning process. With this list, you can decide whether to fix these label issues or remove ambiguous examples from the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a more robust model from noisy labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the label issues manually may be time-consuming, but cleanlab can filter these noisy examples and train a model on the remaining clean data for you automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish a baseline, let's first train and evaluate our original neural network model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_model = get_nn_model()  # note we first re-instantiate the model\n",
    "baseline_model.fit(X=train_texts, y=train_labels, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = baseline_model.predict(test_texts)\n",
    "acc_og = accuracy_score(test_labels, preds)\n",
    "print(f\"\\n Test accuracy of original neural net: {acc_og}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a baseline, let's check if using `CleanLearning` improves our test accuracy.\n",
    "\n",
    "`CleanLearning` provides a wrapper that can be applied to any scikit-learn compatible model. The resulting model object can be used in the same manner, but it will now train more robustly if the data has noisy labels.\n",
    "\n",
    "We can use the same `CleanLearning` object defined above, and  pass the label issues we already computed into `.fit()` via the `label_issues` argument. This accelerates things; if we did not provide the label issues, then they would be recomputed via cross-validation. After that `CleanLearning` simply deletes the examples with label issues and retrains your model on the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl.fit(X=train_texts, labels=train_labels, label_issues=cl.get_label_issues(), clf_kwargs={\"epochs\": num_epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = cl.predict(test_texts)\n",
    "acc_cl = accuracy_score(test_labels, pred_labels)\n",
    "print(f\"Test accuracy of cleanlab's neural net: {acc_cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the test set accuracy slightly improved as a result of the data cleaning. Note that this will not always be the case, especially when we are evaluating on test data that are themselves noisy. The best practice is to run cleanlab to identify potential label issues and then manually review them, before blindly trusting any accuracy metrics. In particular, the most effort should be made to ensure high-quality test data, which is supposed to reflect the expected performance of our model during deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "highlighted_indices = [5204, 22294, 15079]  # check these examples were found in find_label_issues\n",
    "if not all(x in identified_issues.index for x in highlighted_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from ranked_label_issues.\")\n",
    "\n",
    "# Also check that cleanlab has improved prediction accuracy\n",
    "if acc_og >= acc_cl:\n",
    "    raise Exception(\"Cleanlab training failed to improve model accuracy.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text x TensorFlow",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
