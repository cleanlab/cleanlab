{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f361b775-0fb3-4f09-89b9-6672775382bb",
   "metadata": {},
   "source": [
    "# Data Curation with Train vs Test Splits\n",
    "\n",
    "In typical Machine Learning projects, we split our dataset into training data for fitting models and test data to evaluate model performance. For noisy real-world datasets, detecting/correcting errors in the training data is important to train robust models, but it's less recognized that the test set can also be noisy.\n",
    "For accurate model evaluation, it is vital to find and fix issues in the test data as well. Some evaluation metrics are particularly sensitive to outliers and noisy labels.\n",
    "This tutorial demonstrates a way to use [Cleanlab Open Source (CLOS)](https://github.com/cleanlab/cleanlab) to clean both your training and test data, ensuring **robust** model training and **reliable** performance evaluation.\n",
    "\n",
    "Here's how we recommend handling noisy training and test data with CLOS:\n",
    "\n",
    "\n",
    "NEEED TO UPDATE THIS\n",
    "\n",
    "- First focus on detecting issues in the test data. For the best detection, we recommend that you merge your training and test data and then run a Cleanlab Studio Project (which will benefit from more data) -- but only focus on project results for the test data.\n",
    "- Manually review/correct Cleanlab-detected issues in your test data. To avoid bias, we caution against automated correction of test data. Instead, test data changes should be individually verified to ensure they will lead to more accurate model evaluation.\n",
    "- Run a separate Cleanlab Studio project on the training data alone to detect issues in the training data (without any test set information leakage).\n",
    "- Optionally, use automated Cleanlab suggestions to algorithmically refine the training data (or manually review/correct Cleanlab-detected issues in your training data).\n",
    "- Estimate the final model's performance on the cleaned test data. **Do not compare the performance of different ML models estimated across different versions of your test data.** These estimates are incomparable.\n",
    "\n",
    "Consider this tutorial as a blueprint for using Cleanlab Studio in ML projects spanning various data modalities and tasks.\n",
    "Let’s get started!\n",
    "\n",
    "\n",
    "**Note**: We are using tabular data in this tutorial but the approach can apply to other data modalities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab5c7a-6513-43d5-9b5f-7a2da7518825",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "First install and import required dependencies for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d484c-6681-470d-b383-fedac7991f8e",
   "metadata": {},
   "source": [
    "## Install required dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cff72e-5bdf-4b5e-8914-35ee8ba78f25",
   "metadata": {},
   "source": [
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "\n",
    "Make sure to install the version corresponding to this tutorial\n",
    " - E.g. if viewing master branch documentation:\n",
    " - !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "\n",
    "In this tutorial we are using the following version of `cleanlab`: `2.6.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c007ae2-a71f-4b93-86f8-086640d0bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost scikit-learn pandas \"cleanlab[datalab]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0bbf715-47c6-44ea-b15e-89800e62ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import cleanlab\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from cleanlab import Datalab\n",
    "\n",
    "SEED = 123456\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91c529-d932-4b86-9343-d1f8c01c46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanlab.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18731e7e-c5cf-495d-924e-fab1510e6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bbadc-547a-4bb0-8bcf-033c6890ce5e",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f8015-d051-411c-9e03-5659cf3ad956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\n",
    "#     \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/train.csv\"\n",
    "# )\n",
    "# df_test = pd.read_csv(\n",
    "#     \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/test.csv\"\n",
    "# )\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56345196-ead5-4e45-a104-31734cf928f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"clos_train_data.csv\")\n",
    "df_test = pd.read_csv(\"clos_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c86d99-63e7-424a-b991-0b0efbb3c746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37fd76</td>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>missed class frequently -10</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>018bff</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3c9a0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>076d92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68827d</td>\n",
       "      <td>91.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>missed class frequently -10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stud_ID  exam_1  exam_2  exam_3                        notes  \\\n",
       "0  37fd76    99.0    59.0    70.0  missed class frequently -10   \n",
       "1  018bff    94.0    41.0    91.0      great participation +10   \n",
       "2  b3c9a0    91.0    74.0    88.0                          NaN   \n",
       "3  076d92     0.0    79.0    65.0   cheated on exam, gets 0pts   \n",
       "4  68827d    91.0    98.0    75.0  missed class frequently -10   \n",
       "\n",
       "  noisy_letter_grade  \n",
       "0                  D  \n",
       "1                  B  \n",
       "2                  B  \n",
       "3                  F  \n",
       "4                  C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ca8e2-71a9-4699-80b3-352c325ae8e3",
   "metadata": {},
   "source": [
    "## Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd525-7a09-4d8e-811e-44ac1072f438",
   "metadata": {},
   "source": [
    "Before training an XGBoost model, we preprocess the notes and noisy_letter_grade columns into categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5f50e6-d125-4e61-b63e-4004f0c9099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoders for the grade and notes columns\n",
    "grade_le = preprocessing.LabelEncoder()\n",
    "notes_le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Prepare the feature columns\n",
    "train_features = df_train.drop([\"stud_ID\", \"noisy_letter_grade\"], axis=1).copy()\n",
    "train_features[\"notes\"] = notes_le.fit_transform(train_features[\"notes\"])\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "# Encode the label column into a cateogorical feature\n",
    "train_labels = pd.DataFrame(grade_le.fit_transform(df_train[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cd820-7565-4314-9dda-808cbe7c638f",
   "metadata": {},
   "source": [
    "Let's view the training set features after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36c21e9-1c32-4df9-bd87-fffeb8c2175f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_1  exam_2  exam_3 notes\n",
       "0    99.0    59.0    70.0     3\n",
       "1    94.0    41.0    91.0     2\n",
       "2    91.0    74.0    88.0     5\n",
       "3     0.0    79.0    65.0     0\n",
       "4    91.0    98.0    75.0     3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6da7bf-07b6-4a49-b7be-994713688bda",
   "metadata": {},
   "source": [
    "Next we repeat the same preprocessing steps for our clean test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f856a3a-8aae-4836-b146-9ab68d8d1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = df_test.drop(\n",
    "    [\"stud_ID\", \"noisy_letter_grade\"], axis=1\n",
    ").copy()\n",
    "test_features[\"notes\"] = notes_le.transform(test_features[\"notes\"])\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "test_labels = pd.DataFrame(grade_le.transform(df_test[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7379d04a-dcb1-4ada-b199-8d3d72cf9ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 707 entries, 0 to 706\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   exam_1  707 non-null    float64 \n",
      " 1   exam_2  707 non-null    float64 \n",
      " 2   exam_3  707 non-null    float64 \n",
      " 3   notes   707 non-null    category\n",
      "dtypes: category(1), float64(3)\n",
      "memory usage: 17.6 KB\n"
     ]
    }
   ],
   "source": [
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46275634-da56-4e58-9061-8108be2b585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype('object')\n",
    "test_labels = test_labels.astype('object')\n",
    "\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(int)\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(int)\n",
    "\n",
    "preprocessed_train_data = pd.concat([train_features, train_labels], axis=1)\n",
    "preprocessed_train_data[\"stud_ID\"] = df_train[\"stud_ID\"]\n",
    "\n",
    "preprocessed_test_data = pd.concat([test_features, test_labels], axis=1)\n",
    "preprocessed_test_data[\"stud_ID\"] = df_test[\"stud_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2d8d0-c5ac-4e46-9ab0-aee52adaae0d",
   "metadata": {},
   "source": [
    "## Check for Near Duplicate and IID Issues on full dataset using Datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe491e8-4fb6-4b25-b424-617789999ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([preprocessed_train_data, preprocessed_test_data], axis=0).reset_index(drop=True)\n",
    "features_df = full_df.drop([\"noisy_letter_grade\", \"stud_ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f9b556-b9de-4b19-b966-fd8cc3a9a3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "\n",
      "Audit complete. 106 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "    issue_type    score  num_issues\n",
      "near_duplicate 0.588192         106\n",
      "       non_iid 0.595350           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Dataset Information: num_examples: 940, num_classes: 5\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 106\n",
      "Overall dataset quality in terms of this issue: 0.5882\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "732                     True                   0.0     [874, 133, 149]                           0.0\n",
      "205                     True                   0.0               [796]                           0.0\n",
      "593                     True                   0.0               [261]                           0.0\n",
      "204                     True                   0.0               [861]                           0.0\n",
      "541                     True                   0.0                 [3]                           0.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.5953\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "907             False       0.748394\n",
      "791             False       0.753241\n",
      "383             False       0.761824\n",
      "106             False       0.763382\n",
      "771             False       0.764682\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.5953499903340337\n"
     ]
    }
   ],
   "source": [
    "lab = Datalab(data=full_df, label_name=\"noisy_letter_grade\", task=\"classification\")\n",
    "lab.find_issues(features=features_df.to_numpy(), issue_types={\"near_duplicate\": {}, \"non_iid\": {}})\n",
    "lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487cd1b-f74c-449a-88df-48111b4bab2a",
   "metadata": {},
   "source": [
    "We have confirmed there are no `non_IID` issues which is good. Otherwise, we would need to further research where our data came from and why it is not [iid](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables). \n",
    "\n",
    "We can see that we have many `near_duplicate` issues. In fact, we have exact duplicates between our training and test data which is a sign of data leakage! To manage this, let's drop the exact duplicates that are found between our training and test sets from our training set. \n",
    "\n",
    "First, let's filter for the `near_duplicate` issues and then look at a sample of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bc4b2df-1d36-4aa0-997b-beed30184b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[874, 133, 149]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[796]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[261]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[861]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "732                     True                   0.0     [874, 133, 149]   \n",
       "205                     True                   0.0               [796]   \n",
       "593                     True                   0.0               [261]   \n",
       "204                     True                   0.0               [861]   \n",
       "541                     True                   0.0                 [3]   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "732                           0.0  \n",
       "205                           0.0  \n",
       "593                           0.0  \n",
       "204                           0.0  \n",
       "541                           0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_duplicate_results = lab.get_issues(\"near_duplicate\")\n",
    "full_duplicate_results.sort_values(\"near_duplicate_score\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85f8be-6f75-48f6-98a2-34bc5e57e498",
   "metadata": {},
   "source": [
    "We can then filter for exact duplicates below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92dc5eae-05ac-4b28-a6a7-46d5fa297774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[541]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[861]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[796]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[593]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[464]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[385]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[261]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[874, 133, 149]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[205]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[204]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[732, 133, 149]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "3                       True                   0.0               [541]   \n",
       "204                     True                   0.0               [861]   \n",
       "205                     True                   0.0               [796]   \n",
       "261                     True                   0.0               [593]   \n",
       "385                     True                   0.0               [464]   \n",
       "464                     True                   0.0               [385]   \n",
       "541                     True                   0.0                 [3]   \n",
       "593                     True                   0.0               [261]   \n",
       "732                     True                   0.0     [874, 133, 149]   \n",
       "796                     True                   0.0               [205]   \n",
       "861                     True                   0.0               [204]   \n",
       "874                     True                   0.0     [732, 133, 149]   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "3                             0.0  \n",
       "204                           0.0  \n",
       "205                           0.0  \n",
       "261                           0.0  \n",
       "385                           0.0  \n",
       "464                           0.0  \n",
       "541                           0.0  \n",
       "593                           0.0  \n",
       "732                           0.0  \n",
       "796                           0.0  \n",
       "861                           0.0  \n",
       "874                           0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_duplicates = full_duplicate_results[(full_duplicate_results[\"is_near_duplicate_issue\"] == True) & (full_duplicate_results[\"near_duplicate_score\"] == 0.0)].sort_values(\"near_duplicate_score\")\n",
    "exact_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672b692-fc3e-4467-b5c4-4c367b55eb30",
   "metadata": {},
   "source": [
    "To remove the exact duplicates that occur between our training and test sets from our training data, let's define the cutoff index that our training data ends at and then we can drop the rows from our training data that correspond to all indices less than or equal to our cutoff index that are also found in our exact duplicates we just calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df1fa776-a89d-454f-a42d-cfd8b73f2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training index cutoff and find the exact duplicate indices to reference\n",
    "train_idx_cutoff = len(preprocessed_train_data) - 1\n",
    "exact_duplicates_indices = exact_duplicates.index\n",
    "\n",
    "# Filter the indices to drop by which indices in exact duplicates are <= to the index cutoff\n",
    "indices_of_duplicates_to_drop = [idx for idx in exact_duplicates_indices if idx <= train_idx_cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4db8b2-f707-4924-b8ab-354f8b508be9",
   "metadata": {},
   "source": [
    "Now let's view the rows which we will drop from our training data since they are exact duplicates of values we have in our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032be290-318f-42bc-92c9-f7bf87dc12c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "      <th>stud_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>076d92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>90.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>fd8db2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>d5938e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>78.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36284d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fe7277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>a33f92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77c9c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>78.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9afe83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes noisy_letter_grade stud_ID\n",
       "3       0.0    79.0    65.0      0                  4  076d92\n",
       "204    90.0    67.0    77.0      3                  3  fd8db2\n",
       "205    95.0    94.0    89.0      5                  0  d5938e\n",
       "261    78.0    58.0    86.0      1                  1  36284d\n",
       "385    90.0     0.0   100.0      0                  1  fe7277\n",
       "464    72.0     0.0    80.0      0                  4  a33f92\n",
       "541     0.0    79.0    65.0      0                  0  77c9c5\n",
       "593    78.0    58.0    86.0      1                  1  9afe83"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[indices_of_duplicates_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca4891-5f52-4ef8-9f51-731a3caf3096",
   "metadata": {},
   "source": [
    "Then we drop these rows from our training data to get rid of the data leakage issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53b196a4-99eb-43a5-93a4-da5f78f40c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True)\n",
    "train_labels = train_labels.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553d5b2-1ba9-4dca-8110-eda6a8e11281",
   "metadata": {},
   "source": [
    "## Train model with original (noisy) training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36319f39-f563-4f63-913f-821373180350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_labels[\"noisy_letter_grade\"]\n",
    "clf = XGBClassifier(tree_method=\"hist\", enable_categorical=True)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944efa9e-dec4-474f-8007-73587453f8a6",
   "metadata": {},
   "source": [
    "Although curating clean test data does not directly help train a better ML model, more reliable model evaluation can improve our overall ML project. For instance, clean test data can enable better informed decisions regarding when to deploy a model and better model/hyperparameter selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214e30b-4c82-4295-a3b0-68493904836b",
   "metadata": {},
   "source": [
    "## Compute out-of-sample predicted probabilities for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "044c0eb1-299a-4851-b1bf-268d5bce56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "test_labels = test_labels[\"noisy_letter_grade\"].astype(int)\n",
    "\n",
    "num_crossval_folds = 5\n",
    "test_pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    cv=num_crossval_folds,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6121cf2-a074-461b-9860-5d4bb7ff3177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>92.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>90.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>65.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes\n",
       "0      97.0    94.0    76.0      5\n",
       "1      76.0    84.0    67.0      5\n",
       "2      91.0    61.0   100.0      5\n",
       "3      69.0    87.0    70.0      4\n",
       "4     100.0    62.0    61.0      3\n",
       "..      ...     ...     ...    ...\n",
       "228    92.0    74.0    88.0      1\n",
       "229    91.0    90.0    81.0      2\n",
       "230    87.0    74.0    95.0      3\n",
       "231    90.0    57.0    97.0      5\n",
       "232    65.0    69.0    92.0      4\n",
       "\n",
       "[233 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03bc5c8d-f24b-455f-9023-d5667068ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 233 entries, 0 to 232\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   exam_1  233 non-null    float64\n",
      " 1   exam_2  233 non-null    float64\n",
      " 2   exam_3  233 non-null    float64\n",
      " 3   notes   233 non-null    int64  \n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 7.4 KB\n"
     ]
    }
   ],
   "source": [
    "test_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0be670e-f8b4-4703-bcdf-116e784bd035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 233 entries, 0 to 232\n",
      "Series name: noisy_letter_grade\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "233 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.9 KB\n"
     ]
    }
   ],
   "source": [
    "test_labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d9ad1-a69e-4af3-8d4d-ffb76ac47c49",
   "metadata": {},
   "source": [
    "### Evaluate classification model with original (noisy) training data on noisy test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ce2d89f-e832-448d-bfac-9941da15c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to noisy training data, measured on clean test data: 67.4%\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_features)\n",
    "acc_original = accuracy_score(test_labels, preds)\n",
    "print(\n",
    "    f\"Accuracy of model fit to noisy training data, measured on clean test data: {round(acc_original*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e3406-845a-42ff-87d5-a104837234c4",
   "metadata": {},
   "source": [
    "## Use cleanlab to find label issues in test data and then manually correct them\n",
    "Based on the given labels, predicted probabilities, and KNN graph, cleanlab can quickly help us identify suspicious values in our grades table.\n",
    "\n",
    "We use cleanlab’s Datalab class which has several ways of loading the data. In this case, we’ll simply wrap the dataset (features and noisy labels) in a dictionary that is used instantiate a Datalab object such that it can audit our dataset for various types of issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43df278-abfe-40e5-9d48-2df3efea9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab import Datalab\n",
    "\n",
    "test_data = {\"X\": test_features.values, \"y\": test_labels}\n",
    "\n",
    "test_lab = Datalab(test_data, label_name=\"y\")\n",
    "test_lab.find_issues(pred_probs=test_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df763b96-b266-44e8-ba11-128b4b487e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lab.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c82c6-43df-4b4a-b8ad-0d5884ab068a",
   "metadata": {},
   "source": [
    "The above report shows that cleanlab identified many label issues in the data. We can see which examples are estimated to be mislabeled (as well as a numeric quality score quantifying how likely their label is correct) via the get_issues method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7f776-54b3-45b5-9207-715d6d2e90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_issue_results = test_lab.get_issues(\"label\")\n",
    "test_label_issue_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa7728-9499-4125-9f64-5f9b9e1c28e3",
   "metadata": {},
   "source": [
    "To review the most severe label issues, sort the DataFrame above by the `label_score` column (a lower score represents that the label is less likely to be correct).\n",
    "\n",
    "Let’s review some of the most likely label errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b40638-b582-4b2c-93e3-e42e2e1d11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sorted_label_issues = test_label_issue_results.sort_values(\"label_score\").index\n",
    "\n",
    "test_features.iloc[test_sorted_label_issues].assign(\n",
    "    given_label=test_labels[test_sorted_label_issues],\n",
    "    predicted_label=test_label_issue_results[\"predicted_label\"].iloc[test_sorted_label_issues]\n",
    ").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7eeab0-d391-4e9b-85ac-a91a7094618b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e01d13-482e-46b8-a152-f37497150a91",
   "metadata": {},
   "source": [
    "The dataframe above shows the original label (given_label) for examples that cleanlab finds most likely to be mislabeled, as well as an alternative predicted_label for each example.\n",
    "\n",
    "These examples have been labeled incorrectly and should be carefully re-examined - a student with grades of 89, 95 and 73 surely does not deserve a D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50af5b2-6932-4eee-9fd5-bc626591e601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4040b-836b-42bd-9bf5-74407d92889f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d5ee2-2606-44e5-bcd5-1524b1ff4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_to_change = test_features.iloc[test_sorted_label_issues].assign(\n",
    "    given_label=test_labels.iloc[test_sorted_label_issues],\n",
    "    predicted_label=test_label_issue_results[\"predicted_label\"].iloc[test_sorted_label_issues]\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca339a01-018a-4edc-b7df-6acd50101315",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_to_change.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e976421-7bec-4cf1-b9bc-018ccff09f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_to_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90532724-8a76-421a-b99b-5faa3251031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_to_change[[\"given_label\", \"predicted_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac4f2f-288a-4422-8bf2-e5019fe4166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_to_change.loc[:, 'given_label'] = test_features_to_change.loc[:, 'predicted_label']\n",
    "test_features_to_change = test_features_to_change.rename(columns={\"given_label\": \"clean_label\"}).drop(\"predicted_label\", axis=1)\n",
    "test_features_to_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca708d8-7254-4021-b6ec-ba32b6d5fa22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a9aee-a90b-4614-b167-ec41688030c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39270a84-70a7-42e5-ba72-250a10f2aabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd6dd0-a806-4871-9c81-8c5ec07d681a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ca614-fdf0-4449-9008-61cdd2e066cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a11d1-9449-42c1-97ec-3c78d658ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_results = lab.get_issues(\"outlier\")\n",
    "sorted_outliers = outlier_results.sort_values(\"outlier_score\").index\n",
    "\n",
    "train_features.iloc[sorted_outliers].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d42b9e-ca28-4e04-a062-9f206309c10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851611e-6159-4ebe-9239-0a3c21bf3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_results.sort_values(\"outlier_score\")[\"is_outlier_issue\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a773fe-30fb-4a6b-ad54-3211132f7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_issues = outlier_results.query(\"is_outlier_issue\").index\n",
    "outlier_issues = outlier_results.sort_values(\"outlier_score\")[:55].index\n",
    "no_outlier_issues_train_features = train_features.drop(outlier_issues, axis=0).reset_index(drop=True)\n",
    "no_outlier_issues_train_labels = train_labels.drop(outlier_issues, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2d6f1-80d0-4c41-87e1-6900ebd6021b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227bbe67-bbef-441a-bbd3-86275682d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_results = lab.get_issues(\"near_duplicate\")\n",
    "nd_issues = duplicate_results.sort_values(\"near_duplicate_score\")[:200].index\n",
    "no_nd_issues_train_features = train_features.drop(nd_issues, axis=0).reset_index(drop=True)\n",
    "no_nd_issues_train_labels = train_labels.drop(nd_issues, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33de5c-fe4b-484d-b98a-ecd06146ed12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a420e4-4d9f-4892-89c7-ea720e6d4621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deecb24-188a-4775-a971-10a84ba4456e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2624388-ad39-4c88-88c3-51a224ad549a",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization for editing data issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889afff7-3fd5-4092-a14f-e0b3a9023332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e8e3fe-b15f-41e0-87dd-0efb786f2920",
   "metadata": {},
   "source": [
    "We have made some basic edits to improve test performance, so now we will parameterize each one of these edits (eg. what fraction of each issue to delete) to automatically find the best combination of edits to achieve optimal test performance. \n",
    "\n",
    "We will use a basic hyperparameter-tuning library to optimize over these edit-variants + model re-training on the edited datasets with our objective being test performance.\n",
    "\n",
    "In a real-world setting, this would ideally be done on cleaned validation data instead of test data, but we are simplifying the approach for this tutorial.\n",
    "\n",
    "To parametrize our dataset edits, we define a `dict` below containing default settings that we found tend to work well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92d78d-e4a8-4322-bf38-f5a5dae3bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_edit_params = {\n",
    "        \"drop_label_issue\": 0.5,\n",
    "        \"drop_near_duplicate\": 0.2,\n",
    "        \"drop_outlier\": 0.5\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcc027-7e51-4583-ab6d-9fc73f847c90",
   "metadata": {},
   "source": [
    "In english, these choices mean:\n",
    "\n",
    "- `relabel_confidence_threshold`: We relabel any datapoint that is flagged with a label issue, but the model’s predicted label (for another class) has probability > 0.95\n",
    "- `drop_label_issue`: We drop the remaining top 50% of the datapoints flagged with label issues (based on label score). Here we do not drop any of the relabeled datapoints from the prior step.\n",
    "- `drop_outlier`: We drop the top 50% most severe outliers based on outlier score (amongst the set of flagged outliers).\n",
    "- `drop_near_duplicate`: We drop EXTRA COPIES of the top 20% of near duplicates (based on near duplicate score). Never drop the original datapoint though, so at least one copy remains. How do we decide on the original datapoint? Amongst each set of near duplicates, we keep the one that has highest self-confidence score for its given label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87964a-7ca2-4c71-b305-a5101925907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'drop_label_issue': [0.4, 0.5, 0.6],\n",
    "    'drop_near_duplicate': [0.1, 0.2, 0.3],\n",
    "    'drop_outlier': [0.4, 0.5, 0.6],\n",
    "    'relabel_confidence_threshold': [0.9, 0.95, 0.99]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81faef-2d6e-4648-b68e-ea1504a03186",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.get_issues().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074af0c-55b3-4454-b3ea-2324c162111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_results = lab.get_issues(\"near_duplicate\")\n",
    "nd_issues = duplicate_results.sort_values(\"near_duplicate_score\")[:200].index\n",
    "no_nd_issues_train_features = train_features.drop(nd_issues, axis=0).reset_index(drop=True)\n",
    "no_nd_issues_train_labels = train_labels.drop(nd_issues, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f52cd8-408f-4305-8efa-e4405bbbec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_names = ['is_label_issue', 'is_outlier_issue', 'is_near_duplicate_issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74608a13-1fb5-430c-b187-6ab00d248e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.get_issues(\"near_duplicate\").sort_values(\"near_duplicate_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f57a24-cd1e-468a-b38d-4621902a7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.2\n",
    "\n",
    "filtered_df = lab.get_issues(\"near_duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb9c3d-2c3e-4f1a-87b0-54cb8218d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows to drop based on the percentage\n",
    "num_rows = int(len(filtered_df) * percentage)\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef280e4-4bb1-4a0e-9229-92ae7efa576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'near_duplicate_score' and 'near_duplicate_cluster_id' are columns in the DataFrame\n",
    "sorted_df = filtered_df.sort_values(by=\"near_duplicate_score\", ascending=True).reset_index(drop=True)\n",
    "grouped_df = sorted_df.groupby(\"near_duplicate_sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035184e1-a43e-4ef3-be2d-cf2b9b054218",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30d1e8-e83f-4d5c-acc9-605ef49cdda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7cf93-6504-48ae-903a-cb05f6cea8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158c859-d952-4109-a146-d52dce13a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_fraction_ids(\n",
    "    lab_results: pd.DataFrame, bool_column_name: str, percentage: float, asc=True\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    This function returns the IDs of datapoints to drop based on a specified percentage.\n",
    "    \n",
    "    Parameters:\n",
    "    - lab_results (pd.DataFrame): The input DataFrame containing the labeling results.\n",
    "    - bool_column_name (str): The name of the column indicating the issue.\n",
    "    - percentage (float): The percentage of rows to be extracted.\n",
    "    - asc (bool, optional): If True, the rows are sorted in ascending order based on the score column; \n",
    "                            if False, in descending order. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of row indices representing the top specified percentage of rows based on the specified score column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct a filter based on the issue column\n",
    "    filter_condition = lab_results[bool_column_name]\n",
    "\n",
    "    # Create a new DataFrame based on the filter\n",
    "    filtered_df = lab_results[filter_condition]\n",
    "    \n",
    "    # Calculate the number of rows to drop based on the percentage\n",
    "    num_rows = int(len(filtered_df) * percentage)\n",
    "    \n",
    "    # For 'is_near_duplicate_issue', handle duplicates specifically\n",
    "    if bool_column_name == \"is_near_duplicate_issue\":\n",
    "        # Assume 'near_duplicate_score' and 'near_duplicate_cluster_id' are columns in the DataFrame\n",
    "        sorted_df = filtered_df.sort_values(by=\"near_duplicate_score\", ascending=asc).reset_index(drop=True)\n",
    "        grouped_df = sorted_df.groupby(\"near_duplicate_cluster_id\")\n",
    "        \n",
    "        # Initialize an empty list to store the indices to be dropped\n",
    "        drop_indices = []\n",
    "        \n",
    "        # Iterate over each group\n",
    "        for _, group_df in grouped_df:\n",
    "            # Calculate number of rows to drop for this group based on the percentage\n",
    "            group_num_rows = int(len(group_df) * percentage)\n",
    "            if group_num_rows > 0:\n",
    "                # Select the top percentage of rows based on the score, maintaining at least one datapoint\n",
    "                selected_indices = group_df.head(group_num_rows)[\"cleanlab_row_ID\"]\n",
    "                drop_indices.extend(selected_indices)\n",
    "    else:\n",
    "        # For other types of issues, directly select the top percentage of rows based on the score\n",
    "        score_col_name = f\"{bool_column_name}_score\"  # Adjust based on actual score column naming\n",
    "        sorted_df = filtered_df.sort_values(by=score_col_name, ascending=asc)\n",
    "        drop_indices = sorted_df.head(num_rows)[\"cleanlab_row_ID\"]\n",
    "\n",
    "    return list(drop_indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mturk-env",
   "language": "python",
   "name": "mturk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
