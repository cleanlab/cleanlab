{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f361b775-0fb3-4f09-89b9-6672775382bb",
   "metadata": {},
   "source": [
    "# Data Curation with Train vs Test Splits\n",
    "\n",
    "In typical Machine Learning projects, we split our dataset into training data for fitting models and test data to evaluate model performance. For noisy real-world datasets, detecting/correcting errors in the training data is important to train robust models, but it's less recognized that the test set can also be noisy.\n",
    "For accurate model evaluation, it is vital to find and fix issues in the test data as well. Some evaluation metrics are particularly sensitive to outliers and noisy labels.\n",
    "This tutorial demonstrates a way to use [Cleanlab Open Source (CLOS)](https://github.com/cleanlab/cleanlab) to clean both your training and test data, ensuring **robust** model training and **reliable** performance evaluation.\n",
    "\n",
    "Here's how we recommend handling noisy training and test data with CLOS:\n",
    "\n",
    "\n",
    "NEEED TO UPDATE THIS\n",
    "\n",
    "- First focus on detecting issues in the test data. For the best detection, we recommend that you merge your training and test data and then run a Cleanlab Studio Project (which will benefit from more data) -- but only focus on project results for the test data.\n",
    "- Manually review/correct Cleanlab-detected issues in your test data. To avoid bias, we caution against automated correction of test data. Instead, test data changes should be individually verified to ensure they will lead to more accurate model evaluation.\n",
    "- Run a separate Cleanlab Studio project on the training data alone to detect issues in the training data (without any test set information leakage).\n",
    "- Optionally, use automated Cleanlab suggestions to algorithmically refine the training data (or manually review/correct Cleanlab-detected issues in your training data).\n",
    "- Estimate the final model's performance on the cleaned test data. **Do not compare the performance of different ML models estimated across different versions of your test data.** These estimates are incomparable.\n",
    "\n",
    "Consider this tutorial as a blueprint for using Cleanlab Studio in ML projects spanning various data modalities and tasks.\n",
    "Letâ€™s get started!\n",
    "\n",
    "\n",
    "**Note**: We are using tabular data in this tutorial but the approach can apply to other data modalities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab5c7a-6513-43d5-9b5f-7a2da7518825",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "First install and import required dependencies for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d484c-6681-470d-b383-fedac7991f8e",
   "metadata": {},
   "source": [
    "## Install required dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cff72e-5bdf-4b5e-8914-35ee8ba78f25",
   "metadata": {},
   "source": [
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "\n",
    "Make sure to install the version corresponding to this tutorial\n",
    " - E.g. if viewing master branch documentation:\n",
    " - !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "\n",
    "In this tutorial we are using the following version of `cleanlab`: `2.6.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c007ae2-a71f-4b93-86f8-086640d0bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: cleanlab[datalab] in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from xgboost) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tqdm>=4.53.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from cleanlab[datalab]) (4.66.2)\n",
      "Requirement already satisfied: termcolor>=2.4.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from cleanlab[datalab]) (2.4.0)\n",
      "Requirement already satisfied: datasets>=2.7.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from cleanlab[datalab]) (2.18.0)\n",
      "Requirement already satisfied: filelock in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.7.0->cleanlab[datalab]) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (6.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.0->cleanlab[datalab]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.0->cleanlab[datalab]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.0->cleanlab[datalab]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.0->cleanlab[datalab]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.0->cleanlab[datalab]) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets>=2.7.0->cleanlab[datalab]) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.0->cleanlab[datalab]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.0->cleanlab[datalab]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.0->cleanlab[datalab]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mturk/mturk-work/mturk-env/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.0->cleanlab[datalab]) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost scikit-learn pandas \"cleanlab[datalab]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bbf715-47c6-44ea-b15e-89800e62ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import cleanlab\n",
    "import math\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from cleanlab import Datalab\n",
    "\n",
    "SEED = 123456\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f91c529-d932-4b86-9343-d1f8c01c46f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanlab.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18731e7e-c5cf-495d-924e-fab1510e6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bbadc-547a-4bb0-8bcf-033c6890ce5e",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58f8015-d051-411c-9e03-5659cf3ad956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\n",
    "#     \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/train.csv\"\n",
    "# )\n",
    "# df_test = pd.read_csv(\n",
    "#     \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/test.csv\"\n",
    "# )\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56345196-ead5-4e45-a104-31734cf928f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"clos_train_data.csv\")\n",
    "# df_test = pd.read_csv(\"clos_test_data.csv\")\n",
    "\n",
    "df_train = pd.read_csv(\"clos_train_data_v7.csv\")\n",
    "df_test = pd.read_csv(\"clos_test_data_v10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2c86d99-63e7-424a-b991-0b0efbb3c746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>018bff</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b3c9a0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>076d92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68827d</td>\n",
       "      <td>91.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>missed class frequently -10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c80059</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stud_ID  exam_1  exam_2  exam_3                         notes  \\\n",
       "0  018bff    94.0    41.0    91.0       great participation +10   \n",
       "1  b3c9a0    91.0    74.0    88.0                           NaN   \n",
       "2  076d92     0.0    79.0    65.0    cheated on exam, gets 0pts   \n",
       "3  68827d    91.0    98.0    75.0   missed class frequently -10   \n",
       "4  c80059    86.0    89.0    85.0  great final presentation +10   \n",
       "\n",
       "  noisy_letter_grade  \n",
       "0                  B  \n",
       "1                  B  \n",
       "2                  F  \n",
       "3                  C  \n",
       "4                  F  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ca8e2-71a9-4699-80b3-352c325ae8e3",
   "metadata": {},
   "source": [
    "## Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd525-7a09-4d8e-811e-44ac1072f438",
   "metadata": {},
   "source": [
    "Before training an XGBoost model, we preprocess the notes and noisy_letter_grade columns into categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1b5f50e6-d125-4e61-b63e-4004f0c9099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoders for the grade and notes columns\n",
    "grade_le = preprocessing.LabelEncoder()\n",
    "notes_le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Prepare the feature columns\n",
    "train_features = df_train.drop([\"stud_ID\", \"noisy_letter_grade\"], axis=1).copy()\n",
    "train_features[\"notes\"] = notes_le.fit_transform(train_features[\"notes\"])\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "# Encode the label column into a cateogorical feature\n",
    "train_labels = pd.DataFrame(grade_le.fit_transform(df_train[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])\n",
    "\n",
    "\n",
    "# Keep copies of these training features and labels to use for more advanced issue handling later\n",
    "train_features_v2 = train_features.copy()\n",
    "train_labels_v2 = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cd820-7565-4314-9dda-808cbe7c638f",
   "metadata": {},
   "source": [
    "Let's view the training set features after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36c21e9-1c32-4df9-bd87-fffeb8c2175f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_1  exam_2  exam_3 notes\n",
       "0    94.0    41.0    91.0     2\n",
       "1    91.0    74.0    88.0     5\n",
       "2     0.0    79.0    65.0     0\n",
       "3    91.0    98.0    75.0     3\n",
       "4    86.0    89.0    85.0     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6da7bf-07b6-4a49-b7be-994713688bda",
   "metadata": {},
   "source": [
    "Next we repeat the same preprocessing steps for our clean test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f856a3a-8aae-4836-b146-9ab68d8d1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = df_test.drop(\n",
    "    [\"stud_ID\", \"noisy_letter_grade\"], axis=1\n",
    ").copy()\n",
    "test_features[\"notes\"] = notes_le.transform(test_features[\"notes\"])\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "test_labels = pd.DataFrame(grade_le.transform(df_test[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46275634-da56-4e58-9061-8108be2b585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype('object')\n",
    "test_labels = test_labels.astype('object')\n",
    "\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(int)\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(int)\n",
    "\n",
    "preprocessed_train_data = pd.concat([train_features, train_labels], axis=1)\n",
    "preprocessed_train_data[\"stud_ID\"] = df_train[\"stud_ID\"]\n",
    "\n",
    "preprocessed_test_data = pd.concat([test_features, test_labels], axis=1)\n",
    "preprocessed_test_data[\"stud_ID\"] = df_test[\"stud_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2d8d0-c5ac-4e46-9ab0-aee52adaae0d",
   "metadata": {},
   "source": [
    "## Check for Near Duplicate and IID Issues on full dataset using Datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe491e8-4fb6-4b25-b424-617789999ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([preprocessed_train_data, preprocessed_test_data], axis=0).reset_index(drop=True)\n",
    "features_df = full_df.drop([\"noisy_letter_grade\", \"stud_ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f9b556-b9de-4b19-b966-fd8cc3a9a3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "\n",
      "Audit complete. 87 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "    issue_type    score  num_issues\n",
      "near_duplicate 0.596413          87\n",
      "       non_iid 0.090307           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Dataset Information: num_examples: 856, num_classes: 5\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 87\n",
      "Overall dataset quality in terms of this issue: 0.5964\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score                            near_duplicate_sets  distance_to_nearest_neighbor\n",
      "715                     True                   0.0  [714, 707, 706, 709, 710, 711, 712, 713, 708]                           0.0\n",
      "260                     True                   0.0                                          [592]                           0.0\n",
      "2                       True                   0.0                                          [540]                           0.0\n",
      "384                     True                   0.0                                          [463]                           0.0\n",
      "707                     True                   0.0  [714, 706, 709, 710, 711, 712, 713, 708, 715]                           0.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.0903\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "711             False       0.621309\n",
      "712             False       0.621351\n",
      "710             False       0.621507\n",
      "713             False       0.621629\n",
      "709             False       0.621943\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.09030651041152918\n"
     ]
    }
   ],
   "source": [
    "lab = Datalab(data=full_df, label_name=\"noisy_letter_grade\", task=\"classification\")\n",
    "lab.find_issues(features=features_df.to_numpy(), issue_types={\"near_duplicate\": {}, \"non_iid\": {}})\n",
    "lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487cd1b-f74c-449a-88df-48111b4bab2a",
   "metadata": {},
   "source": [
    "cleanlab helped confirm there are no `non_IID` issues which is good. Otherwise, we'd need to further research where our data came from and why it is not [iid](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables). \n",
    "\n",
    "We can see that we have many `near_duplicate` issues. In fact, we have exact duplicates between our training and test data which is a sign of data leakage! To manage this, let's drop the exact duplicates that are found between our training and test sets from our training set. \n",
    "\n",
    "cleanlab helps us filter for the `near_duplicate` issues using our `DataLab` results. Then we can look at a sample of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc4b2df-1d36-4aa0-997b-beed30184b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 709, 710, 711, 712, 713, 708]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[592]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[540]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[463]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 706, 709, 710, 711, 712, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score  \\\n",
       "715                     True                   0.0   \n",
       "260                     True                   0.0   \n",
       "2                       True                   0.0   \n",
       "384                     True                   0.0   \n",
       "707                     True                   0.0   \n",
       "\n",
       "                               near_duplicate_sets  \\\n",
       "715  [714, 707, 706, 709, 710, 711, 712, 713, 708]   \n",
       "260                                          [592]   \n",
       "2                                            [540]   \n",
       "384                                          [463]   \n",
       "707  [714, 706, 709, 710, 711, 712, 713, 708, 715]   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "715                           0.0  \n",
       "260                           0.0  \n",
       "2                             0.0  \n",
       "384                           0.0  \n",
       "707                           0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_duplicate_results = lab.get_issues(\"near_duplicate\")\n",
    "full_duplicate_results.sort_values(\"near_duplicate_score\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85f8be-6f75-48f6-98a2-34bc5e57e498",
   "metadata": {},
   "source": [
    "We can then filter for exact duplicates below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92dc5eae-05ac-4b28-a6a7-46d5fa297774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[540]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[592]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[463]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[384]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[260]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 709, 710, 711, 712, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 706, 709, 710, 711, 712, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 709, 710, 711, 712, 713, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 710, 711, 712, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 709, 711, 712, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 709, 710, 712, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 709, 710, 711, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 709, 710, 711, 712, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[707, 706, 709, 710, 711, 712, 713, 708, 715]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[714, 707, 706, 709, 710, 711, 712, 713, 708]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score  \\\n",
       "2                       True                   0.0   \n",
       "260                     True                   0.0   \n",
       "384                     True                   0.0   \n",
       "463                     True                   0.0   \n",
       "540                     True                   0.0   \n",
       "592                     True                   0.0   \n",
       "706                     True                   0.0   \n",
       "707                     True                   0.0   \n",
       "708                     True                   0.0   \n",
       "709                     True                   0.0   \n",
       "710                     True                   0.0   \n",
       "711                     True                   0.0   \n",
       "712                     True                   0.0   \n",
       "713                     True                   0.0   \n",
       "714                     True                   0.0   \n",
       "715                     True                   0.0   \n",
       "\n",
       "                               near_duplicate_sets  \\\n",
       "2                                            [540]   \n",
       "260                                          [592]   \n",
       "384                                          [463]   \n",
       "463                                          [384]   \n",
       "540                                            [2]   \n",
       "592                                          [260]   \n",
       "706  [714, 707, 709, 710, 711, 712, 713, 708, 715]   \n",
       "707  [714, 706, 709, 710, 711, 712, 713, 708, 715]   \n",
       "708  [714, 707, 706, 709, 710, 711, 712, 713, 715]   \n",
       "709  [714, 707, 706, 710, 711, 712, 713, 708, 715]   \n",
       "710  [714, 707, 706, 709, 711, 712, 713, 708, 715]   \n",
       "711  [714, 707, 706, 709, 710, 712, 713, 708, 715]   \n",
       "712  [714, 707, 706, 709, 710, 711, 713, 708, 715]   \n",
       "713  [714, 707, 706, 709, 710, 711, 712, 708, 715]   \n",
       "714  [707, 706, 709, 710, 711, 712, 713, 708, 715]   \n",
       "715  [714, 707, 706, 709, 710, 711, 712, 713, 708]   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "2                             0.0  \n",
       "260                           0.0  \n",
       "384                           0.0  \n",
       "463                           0.0  \n",
       "540                           0.0  \n",
       "592                           0.0  \n",
       "706                           0.0  \n",
       "707                           0.0  \n",
       "708                           0.0  \n",
       "709                           0.0  \n",
       "710                           0.0  \n",
       "711                           0.0  \n",
       "712                           0.0  \n",
       "713                           0.0  \n",
       "714                           0.0  \n",
       "715                           0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_duplicates = full_duplicate_results[(full_duplicate_results[\"is_near_duplicate_issue\"] == True) & (full_duplicate_results[\"near_duplicate_score\"] == 0.0)].sort_values(\"near_duplicate_score\")\n",
    "exact_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672b692-fc3e-4467-b5c4-4c367b55eb30",
   "metadata": {},
   "source": [
    "To remove the exact duplicates that occur between our training and test sets from our training data, let's define the cutoff index that our training data ends at and then we can drop the rows from our training data that correspond to all indices less than or equal to our cutoff index that are also found in our exact duplicates we just calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df1fa776-a89d-454f-a42d-cfd8b73f2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training index cutoff and find the exact duplicate indices to reference\n",
    "train_idx_cutoff = len(preprocessed_train_data) - 1\n",
    "exact_duplicates_indices = exact_duplicates.index\n",
    "\n",
    "# Filter the indices to drop by which indices in exact duplicates are <= to the index cutoff\n",
    "indices_of_duplicates_to_drop = [idx for idx in exact_duplicates_indices if idx <= train_idx_cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4db8b2-f707-4924-b8ab-354f8b508be9",
   "metadata": {},
   "source": [
    "Now let's view the rows which we will drop from our training data since they are exact duplicates of values we have in our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "032be290-318f-42bc-92c9-f7bf87dc12c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "      <th>stud_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>076d92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>78.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36284d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fe7277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>a33f92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77c9c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>78.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9afe83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>99.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37fd76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes noisy_letter_grade stud_ID\n",
       "2       0.0    79.0    65.0      0                  4  076d92\n",
       "260    78.0    58.0    86.0      1                  1  36284d\n",
       "384    90.0     0.0   100.0      0                  1  fe7277\n",
       "463    72.0     0.0    80.0      0                  4  a33f92\n",
       "540     0.0    79.0    65.0      0                  0  77c9c5\n",
       "592    78.0    58.0    86.0      1                  1  9afe83\n",
       "706    99.0    59.0    70.0      3                  3  37fd76\n",
       "707    99.0    59.0    70.0      3                  3  37fd76\n",
       "708    99.0    59.0    70.0      3                  3  37fd76\n",
       "709    99.0    59.0    70.0      3                  3  37fd76\n",
       "710    99.0    59.0    70.0      3                  3  37fd76\n",
       "711    99.0    59.0    70.0      3                  3  37fd76\n",
       "712    99.0    59.0    70.0      3                  3  37fd76\n",
       "713    99.0    59.0    70.0      3                  3  37fd76\n",
       "714    99.0    59.0    70.0      3                  3  37fd76\n",
       "715    99.0    59.0    70.0      3                  3  37fd76"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[indices_of_duplicates_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca4891-5f52-4ef8-9f51-731a3caf3096",
   "metadata": {},
   "source": [
    "Then we drop these rows from our training data to get rid of the data leakage issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b196a4-99eb-43a5-93a4-da5f78f40c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True)\n",
    "train_labels = train_labels.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553d5b2-1ba9-4dca-8110-eda6a8e11281",
   "metadata": {},
   "source": [
    "## Train model with original (noisy) training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36319f39-f563-4f63-913f-821373180350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_labels[\"noisy_letter_grade\"]\n",
    "clf = XGBClassifier(tree_method=\"hist\", enable_categorical=True)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944efa9e-dec4-474f-8007-73587453f8a6",
   "metadata": {},
   "source": [
    "Although curating clean test data does not directly help train a better ML model, more reliable model evaluation can improve our overall ML project. For instance, clean test data can enable better informed decisions regarding when to deploy a model and better model/hyperparameter selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214e30b-4c82-4295-a3b0-68493904836b",
   "metadata": {},
   "source": [
    "## Compute out-of-sample predicted probabilities for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "044c0eb1-299a-4851-b1bf-268d5bce56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "test_labels = test_labels[\"noisy_letter_grade\"].astype(int)\n",
    "\n",
    "num_crossval_folds = 5\n",
    "test_pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    cv=num_crossval_folds,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e3406-845a-42ff-87d5-a104837234c4",
   "metadata": {},
   "source": [
    "## Use Datalab to find label issues in test data and then manually correct them\n",
    "Based on the given labels and predicted probabilities, cleanlab can quickly help us identify suspicious values in our grades table.\n",
    "\n",
    "We use cleanlabâ€™s Datalab class which has several ways of loading the data. In this case, weâ€™ll simply wrap the dataset (features and noisy labels) in a dictionary that is used instantiate a Datalab object such that it can audit our dataset for various types of issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c43df278-abfe-40e5-9d48-2df3efea9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 45 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "           issue_type    score  num_issues\n",
      "                label 0.621429          45\n",
      "                 null 1.000000           0\n",
      "              outlier 0.381558           0\n",
      "       near_duplicate 0.596489           0\n",
      "              non_iid 0.592292           0\n",
      "      class_imbalance 0.100000           0\n",
      "underperforming_group 1.000000           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Dataset Information: num_examples: 140, num_classes: 5\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 45\n",
      "Overall dataset quality in terms of this issue: 0.6214\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score  given_label  predicted_label\n",
      "83             True     0.000121            0                2\n",
      "109           False     0.000376            4                0\n",
      "2              True     0.001335            4                1\n",
      "15             True     0.001360            4                1\n",
      "112            True     0.001372            3                1\n",
      "\n",
      "\n",
      "----------------------- null issues ------------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).\n",
      "        \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_null_issue  null_score\n",
      "0            False         1.0\n",
      "102          False         1.0\n",
      "101          False         1.0\n",
      "100          False         1.0\n",
      "99           False         1.0\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.3816\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_outlier_issue  outlier_score\n",
      "16              False       0.108412\n",
      "30              False       0.119039\n",
      "115             False       0.123894\n",
      "114             False       0.124070\n",
      "102             False       0.131540\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.5965\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "22                    False              0.151562                  []                      0.000016\n",
      "25                    False              0.151562                  []                      0.000016\n",
      "46                    False              0.152346                  []                      0.000016\n",
      "96                    False              0.152346                  []                      0.000016\n",
      "87                    False              0.155761                  []                      0.000016\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.5923\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "32              False       0.784825\n",
      "110             False       0.794173\n",
      "3               False       0.804432\n",
      "115             False       0.807789\n",
      "39              False       0.808601\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.5922921666667894\n",
      "\n",
      "\n",
      "------------------ class_imbalance issues ------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples belonging to the most under-represented class in the dataset.\n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.1000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_class_imbalance_issue  class_imbalance_score  given_label\n",
      "82                     False                    0.1            4\n",
      "90                     False                    0.1            4\n",
      "93                     False                    0.1            4\n",
      "86                     False                    0.1            4\n",
      "15                     False                    0.1            4\n",
      "\n",
      "Additional Information: \n",
      "Rarest Class: NA\n",
      "\n",
      "\n",
      "--------------- underperforming_group issues ---------------\n",
      "\n",
      "About this issue:\n",
      "\tAn underperforming group refers to a collection of â€œhardâ€ examples\n",
      "    for which the model predictions are poor. The quality of predictions is\n",
      "    computed using the :py:func:`get_self_confidence_for_each_label <cleanlab.rank.get_self_confidence_for_each_label>` function.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_underperforming_group_issue  underperforming_group_score\n",
      "0                             False                          1.0\n",
      "102                           False                          1.0\n",
      "101                           False                          1.0\n",
      "100                           False                          1.0\n",
      "99                            False                          1.0\n"
     ]
    }
   ],
   "source": [
    "test_data = {\"X\": test_features.values, \"y\": test_labels}\n",
    "\n",
    "test_lab = Datalab(data=test_data, label_name=\"y\", task=\"classification\") \n",
    "test_lab.find_issues(features=test_features.to_numpy(), pred_probs=test_pred_probs)\n",
    "test_lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c82c6-43df-4b4a-b8ad-0d5884ab068a",
   "metadata": {},
   "source": [
    "The above report shows that cleanlab identified many label issues in the data. We can see which examples are estimated to be mislabeled (as well as a numeric quality score quantifying how likely their label is correct) via the get_issues method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77c7f776-54b3-45b5-9207-715d6d2e90c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_score</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.942174</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.779307</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.830184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.795155</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_label_issue  label_score  given_label  predicted_label\n",
       "0           False     0.942174            1                1\n",
       "1           False     0.779307            2                2\n",
       "2            True     0.001335            4                1\n",
       "3           False     0.830184            1                1\n",
       "4           False     0.795155            3                3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_issue_results = test_lab.get_issues(\"label\")\n",
    "test_label_issue_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c52c4191-651a-423a-af79-50fdb1ba7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_issues = test_label_issue_results[test_label_issue_results[\"is_label_issue\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa7728-9499-4125-9f64-5f9b9e1c28e3",
   "metadata": {},
   "source": [
    "To review the most severe label issues, sort the DataFrame above by the `label_score` column (a lower score represents that the label is less likely to be correct).\n",
    "\n",
    "Letâ€™s review some of the most likely label errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b40638-b582-4b2c-93e3-e42e2e1d11dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>86.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>95.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes  given_label  predicted_label  label_score\n",
       "83     87.0    74.0    86.0      4            0                2     0.000121\n",
       "2      72.0    91.0    91.0      5            4                1     0.001335\n",
       "15     72.0    90.0    98.0      5            4                1     0.001360\n",
       "112    86.0    85.0    89.0      5            3                1     0.001372\n",
       "98     95.0    80.0    86.0      5            4                1     0.003727"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sorted_label_issues = test_label_issues.sort_values(\"label_score\").index\n",
    "\n",
    "test_features.iloc[test_sorted_label_issues].assign(\n",
    "    given_label=test_labels[test_sorted_label_issues],\n",
    "    predicted_label=test_label_issue_results[\"predicted_label\"].iloc[test_sorted_label_issues],\n",
    "    label_score=test_label_issues[\"label_score\"]\n",
    ").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e01d13-482e-46b8-a152-f37497150a91",
   "metadata": {},
   "source": [
    "The dataframe above shows the original label (`given_label`) for examples that cleanlab finds most likely to be mislabeled, as well as an alternative `predicted_label` for each example.\n",
    "\n",
    "These examples have been labeled incorrectly and should be carefully re-examined by inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d7d5ee2-2606-44e5-bcd5-1524b1ff4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_issues_to_fix = test_features.iloc[test_sorted_label_issues].assign(\n",
    "    given_label=test_labels.iloc[test_sorted_label_issues],\n",
    "    predicted_label=test_label_issue_results[\"predicted_label\"].iloc[test_sorted_label_issues],\n",
    "    label_score=test_label_issues[\"label_score\"]\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "303f604e-57b5-44b7-9a32-8137957c9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_drop_from_test_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f91db0d-df14-452c-b8ed-b78728a7fe81",
   "metadata": {},
   "source": [
    "cleanlab found the label issues below in our test data, so let's inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ee9117a-d77d-40e1-af75-2c744d484e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>86.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>95.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>87.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>79.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>99.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>64.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>72.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>93.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>99.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>92.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.069073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>69.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>93.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>82.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>83.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.137817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>80.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>66.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>86.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.160483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>91.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.219128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>67.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.232497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>96.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.234414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>64.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.256294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.258879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>86.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.288535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>71.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.369903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.399274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.424860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>92.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.440141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes  given_label  predicted_label  label_score\n",
       "83     87.0    74.0    86.0      4            0                2     0.000121\n",
       "2      72.0    91.0    91.0      5            4                1     0.001335\n",
       "15     72.0    90.0    98.0      5            4                1     0.001360\n",
       "112    86.0    85.0    89.0      5            3                1     0.001372\n",
       "98     95.0    80.0    86.0      5            4                1     0.003727\n",
       "93     80.0    60.0    80.0      5            4                1     0.004443\n",
       "79     71.0    78.0    80.0      1            3                1     0.005022\n",
       "127    87.0    80.0    65.0      1            1                0     0.005130\n",
       "102    95.0    81.0    76.0      5            1                3     0.005515\n",
       "58     79.0    73.0    78.0      5            2                4     0.005803\n",
       "69     99.0    86.0    74.0      5            3                1     0.006346\n",
       "95     95.0    87.0    82.0      3            0                2     0.021102\n",
       "33     65.0    85.0    80.0      2            1                3     0.021491\n",
       "81     64.0    73.0    79.0      1            1                3     0.021566\n",
       "108    72.0    80.0    69.0      5            2                3     0.022899\n",
       "77     93.0    98.0    75.0      5            3                0     0.025057\n",
       "139    87.0    74.0    95.0      3            2                4     0.030187\n",
       "18     72.0    69.0    81.0      4            3                2     0.031202\n",
       "26     99.0    86.0    95.0      3            1                0     0.038090\n",
       "55     92.0    99.0    87.0      4            1                0     0.055950\n",
       "19     86.0    97.0    95.0      5            0                1     0.064619\n",
       "5      90.0    99.0    90.0      5            0                1     0.064682\n",
       "6      68.0    82.0    97.0      5            1                3     0.069073\n",
       "80     69.0    85.0    79.0      5            2                1     0.082654\n",
       "124    97.0    97.0    92.0      4            1                0     0.083220\n",
       "21     93.0    68.0    86.0      4            2                0     0.110317\n",
       "99     82.0    94.0    99.0      3            1                4     0.125628\n",
       "25     83.0    80.0    86.0      5            1                4     0.137817\n",
       "130    80.0    98.0    84.0      2            0                1     0.143075\n",
       "107    66.0    83.0    96.0      5            3                1     0.153613\n",
       "91     86.0    67.0    76.0      4            3                2     0.160483\n",
       "40     91.0    92.0    70.0      5            3                1     0.171490\n",
       "28     62.0    64.0    63.0      5            3                2     0.219128\n",
       "118    86.0    87.0    77.0      5            1                2     0.222507\n",
       "128    67.0    87.0    95.0      4            2                1     0.232497\n",
       "111    96.0    83.0    73.0      1            0                3     0.234414\n",
       "36     64.0    75.0    90.0      5            2                1     0.248218\n",
       "11     83.0    79.0    92.0      4            2                4     0.256294\n",
       "88     89.0    95.0    72.0      5            1                3     0.258879\n",
       "51     86.0    91.0    86.0      3            2                0     0.260394\n",
       "71     93.0    88.0    79.0      4            2                4     0.288535\n",
       "63     71.0    92.0    94.0      5            1                4     0.369903\n",
       "64     90.0    88.0    84.0      4            2                4     0.399274\n",
       "14     90.0    77.0    99.0      2            0                4     0.424860\n",
       "89     92.0    90.0    77.0      2            0                4     0.440141"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_issues_to_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c4c6c-ce5b-4863-9675-471ff7596229",
   "metadata": {},
   "source": [
    "After manually inspecting our label issues above, we can add the indices for the label issues we want to remove from our data to our list we defined previously. \n",
    "\n",
    "Remember to ALWAYS inspect and manually handle label issues in your test data and to NEVER handle them automatically. \n",
    "\n",
    "Below, we add each of our label issues in our test data to a list of indices we will drop to clean our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e218d04-0729-4f42-b264-51c73601ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_drop_from_test_data += list(test_label_issues_to_fix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e2bdb41-321e-4929-aa01-1f60948b9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features.drop(indices_to_drop_from_test_data, axis=0).reset_index(drop=True)\n",
    "test_labels = test_labels.drop(indices_to_drop_from_test_data, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9aba3f-1413-4a04-a74d-eb2febaf6763",
   "metadata": {},
   "source": [
    "### Evaluate classification model with original (noisy) training data on clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ce2d89f-e832-448d-bfac-9941da15c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to noisy training data, measured on clean test data: 72.6%\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_features)\n",
    "acc_original = accuracy_score(test_labels, preds)\n",
    "print(\n",
    "    f\"Accuracy of model fit to noisy training data, measured on clean test data: {round(acc_original*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f5e46-8985-4a7c-bc6f-9f7be509b787",
   "metadata": {},
   "source": [
    "##  Compute out-of-sample predicted probabilities for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f437756-112e-4531-84fc-6ceadd0c9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crossval_folds = 5\n",
    "pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    cv=num_crossval_folds,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323134e9-8339-4847-9a1d-455ca0a6f449",
   "metadata": {},
   "source": [
    "## Use Datalab to find label issues in training data and then manually correct them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e9ed45b-67b1-4531-8d8a-93439caa7eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 357 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "           issue_type    score  num_issues\n",
      "                label 0.734286         209\n",
      "              outlier 0.340853          78\n",
      "       near_duplicate 0.597323          70\n",
      "                 null 1.000000           0\n",
      "              non_iid 0.477806           0\n",
      "      class_imbalance 0.154286           0\n",
      "underperforming_group 0.938766           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Dataset Information: num_examples: 700, num_classes: 5\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 209\n",
      "Overall dataset quality in terms of this issue: 0.7343\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score  given_label  predicted_label\n",
      "269            True     0.000134            4                1\n",
      "405            True     0.000171            1                2\n",
      "213            True     0.000189            4                0\n",
      "194            True     0.000224            4                0\n",
      "620            True     0.000331            0                2\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 78\n",
      "Overall dataset quality in terms of this issue: 0.3409\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_outlier_issue  outlier_score\n",
      "693              True   2.484717e-46\n",
      "391              True   7.054457e-29\n",
      "373              True   6.156041e-26\n",
      "312              True   7.303683e-23\n",
      "395              True   1.033103e-19\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 70\n",
      "Overall dataset quality in terms of this issue: 0.5973\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "88                      True          4.289236e-12               [426]                  2.220446e-16\n",
      "426                     True          4.289236e-12                [88]                  2.220446e-16\n",
      "634                     True          4.595604e-05               [281]                  2.379106e-09\n",
      "281                     True          4.595604e-05               [634]                  2.379106e-09\n",
      "259                     True          1.504883e-04          [364, 386]                  7.791060e-09\n",
      "\n",
      "\n",
      "----------------------- null issues ------------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).\n",
      "        \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_null_issue  null_score\n",
      "0            False         1.0\n",
      "462          False         1.0\n",
      "463          False         1.0\n",
      "464          False         1.0\n",
      "465          False         1.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.4778\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "580             False       0.731657\n",
      "107             False       0.734694\n",
      "342             False       0.735018\n",
      "139             False       0.761417\n",
      "180             False       0.767074\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.47780627364454403\n",
      "\n",
      "\n",
      "------------------ class_imbalance issues ------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples belonging to the most under-represented class in the dataset.\n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.1543\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_class_imbalance_issue  class_imbalance_score  given_label\n",
      "607                     False               0.154286            4\n",
      "445                     False               0.154286            4\n",
      "557                     False               0.154286            4\n",
      "167                     False               0.154286            4\n",
      "482                     False               0.154286            4\n",
      "\n",
      "Additional Information: \n",
      "Rarest Class: NA\n",
      "\n",
      "\n",
      "--------------- underperforming_group issues ---------------\n",
      "\n",
      "About this issue:\n",
      "\tAn underperforming group refers to a collection of â€œhardâ€ examples\n",
      "    for which the model predictions are poor. The quality of predictions is\n",
      "    computed using the :py:func:`get_self_confidence_for_each_label <cleanlab.rank.get_self_confidence_for_each_label>` function.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.9388\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_underperforming_group_issue  underperforming_group_score\n",
      "0                             False                          1.0\n",
      "462                           False                          1.0\n",
      "463                           False                          1.0\n",
      "464                           False                          1.0\n",
      "465                           False                          1.0\n"
     ]
    }
   ],
   "source": [
    "train_data = {\"X\": train_features.values, \"y\": train_labels}\n",
    "\n",
    "train_lab = Datalab(data=train_data, label_name=\"y\", task=\"classification\")\n",
    "train_lab.find_issues(features=train_features.to_numpy(), pred_probs=pred_probs)\n",
    "train_lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25afe46c-a521-483c-b168-728c76d970dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  2,   3,   7,   9,  14,  15,  19,  24,  25,  26,\n",
       "       ...\n",
       "       665, 672, 674, 678, 680, 688, 691, 692, 695, 696],\n",
       "      dtype='int64', length=209)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_issue_results = train_lab.get_issues(\"label\")\n",
    "label_issues_idx = label_issue_results[label_issue_results[\"is_label_issue\"] == True].index\n",
    "label_issues_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6efcf06f-cc40-4964-87df-5204d3b1b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicates = train_lab.get_issues(\"near_duplicate\")\n",
    "near_duplicates_idx = near_duplicates[near_duplicates[\"is_near_duplicate_issue\"] == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bc87d72-bbd5-4ed2-bc38-2218862ddfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  0,   4,   9,  29,  47,  65,  93,  95,  99, 124, 157, 172, 182, 191,\n",
       "       195, 198, 209, 229, 230, 235, 237, 245, 250, 278, 280, 285, 312, 331,\n",
       "       340, 344, 352, 355, 360, 362, 365, 373, 382, 391, 392, 395, 407, 421,\n",
       "       439, 440, 455, 463, 465, 470, 483, 488, 491, 499, 508, 521, 526, 563,\n",
       "       566, 571, 572, 576, 579, 590, 599, 600, 612, 613, 627, 637, 641, 642,\n",
       "       656, 665, 670, 676, 680, 681, 693, 697],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = train_lab.get_issues(\"outlier\")\n",
    "outliers_idx = outliers[outliers[\"is_outlier_issue\"] == True].index\n",
    "outliers_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c70be3e-0ba2-4e3e-8c50-359d402ca1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_drop = list(set(list(label_issues_idx) + list(near_duplicates_idx) + list(outliers_idx)))\n",
    "len(idx_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08080458-0cd7-447d-80e6-384cb8d31eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.drop(idx_to_drop, axis=0).reset_index(drop=True)\n",
    "train_labels = train_labels.drop(idx_to_drop, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8560d6-70e3-4cee-944e-49f047b9fff4",
   "metadata": {},
   "source": [
    "## Train model on clean training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "009bb215-4d26-47da-a230-d0ccf4122629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_clf = XGBClassifier(tree_method=\"hist\", enable_categorical=True)\n",
    "clean_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f83f8-07e6-4702-a39e-94336268bfef",
   "metadata": {},
   "source": [
    "### Evaluate classification model with clean training on clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcaeda51-9b24-4c04-889d-7e63563594fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to clean training data, measured on clean test data: 80.0%\n"
     ]
    }
   ],
   "source": [
    "clean_preds = clean_clf.predict(test_features)\n",
    "acc_clean = accuracy_score(test_labels, clean_preds)\n",
    "print(\n",
    "    f\"Accuracy of model fit to clean training data, measured on clean test data: {round(acc_clean*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2624388-ad39-4c88-88c3-51a224ad549a",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization for editing data issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8e3fe-b15f-41e0-87dd-0efb786f2920",
   "metadata": {},
   "source": [
    "We have made some basic edits to improve test performance, so now we will parameterize each one of these edits (eg. what fraction of each issue to delete) to automatically find the best combination of edits to achieve optimal test performance. \n",
    "\n",
    "We will use a basic hyperparameter-tuning library to optimize over these edit-variants + model re-training on the edited datasets with our objective being test performance.\n",
    "\n",
    "In a real-world setting, this would ideally be done on cleaned validation data instead of test data, but we are simplifying the approach for this tutorial.\n",
    "\n",
    "To parametrize our dataset edits, we define a `dict` below containing default settings that we found tend to work well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d92d78d-e4a8-4322-bf38-f5a5dae3bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_edit_params = {\n",
    "        \"drop_label_issue\": 0.5,\n",
    "        \"drop_near_duplicate\": 0.2,\n",
    "        \"drop_outlier\": 0.5\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcc027-7e51-4583-ab6d-9fc73f847c90",
   "metadata": {},
   "source": [
    "In english, these choices mean:\n",
    "\n",
    "- `drop_label_issue`: We drop the remaining top 50% of the datapoints flagged with label issues (based on label score). Here we do not drop any of the relabeled datapoints from the prior step.\n",
    "- `drop_outlier`: We drop the top 50% most severe outliers based on outlier score (amongst the set of flagged outliers).\n",
    "- `drop_near_duplicate`: We drop EXTRA COPIES of the top 20% of near duplicates (based on near duplicate score). Never drop the original datapoint though, so at least one copy remains. How do we decide on the original datapoint? Amongst each set of near duplicates, we keep the one that has highest self-confidence score for its given label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465b144-f0d1-49a6-a0f7-852fdb2bd71c",
   "metadata": {},
   "source": [
    "`cleanlab`'s `DataLab` object helps us define, in sorted (ascending) order based on the severity of issue score, our issues below. We will use in our hyperparameter optimization to find what combination of datapoints we drop improves our ML model results the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0541a89d-6794-449a-a880-b52e963d14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues = train_lab.get_issues(\"label\").query(\"is_label_issue\").sort_values(\"label_score\")\n",
    "near_duplicates = train_lab.get_issues(\"near_duplicate\").query(\"is_near_duplicate_issue\").sort_values(\"near_duplicate_score\")\n",
    "outliers = train_lab.get_issues(\"outlier\").query(\"is_outlier_issue\").sort_values(\"outlier_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9c75d9d2-ea32-4e55-8b57-7f9ad73810d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_features, train_labels, label_issues, near_duplicates, outliers, drop_label_issue, drop_near_duplicate, drop_outlier):\n",
    "    \"\"\"\n",
    "    Preprocesses the training data by dropping a specified percentage of data points identified as label issues,\n",
    "    near duplicates, and outliers based on the full datasets provided for each issue type.\n",
    "    \n",
    "    Args:\n",
    "        train_features (pd.DataFrame): DataFrame containing the training features.\n",
    "        train_labels (pd.Series): Series containing the training labels.\n",
    "        label_issues (pd.DataFrame): DataFrame containing data points with label issues.\n",
    "        near_duplicates (pd.DataFrame): DataFrame containing data points identified as near duplicates.\n",
    "        outliers (pd.DataFrame): DataFrame containing data points identified as outliers.\n",
    "        drop_label_issue (float): Percentage of label issue data points to drop.\n",
    "        drop_near_duplicate (float): Percentage of near duplicate data points to drop.\n",
    "        drop_outlier (float): Percentage of outlier data points to drop.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned training features.\n",
    "        pd.Series: The cleaned training labels.\n",
    "    \"\"\"\n",
    "    # Extract indices for each type of issue\n",
    "    label_issues_idx = label_issues.index.tolist()\n",
    "    near_duplicates_idx = near_duplicates.index.tolist()\n",
    "    outliers_idx = outliers.index.tolist()\n",
    "    \n",
    "    # Calculate the number of each type of data point to drop except near duplicates, which requires separate logic\n",
    "    num_label_issues_to_drop = int(len(label_issues_idx) * drop_label_issue)\n",
    "    num_outliers_to_drop = int(len(outliers_idx) * drop_outlier)\n",
    "\n",
    "    # Calculate number of near duplicates to drop\n",
    "    # Assuming the 'near_duplicate_sets' are lists of indices (integers) of near duplicates\n",
    "    clusters = []\n",
    "    for i in near_duplicates_idx:\n",
    "        # Create a set for each cluster, add the current index to its near duplicate set\n",
    "        cluster = set(near_duplicates.at[i, 'near_duplicate_sets'])\n",
    "        cluster.add(i)\n",
    "        clusters.append(cluster)\n",
    "    \n",
    "    # Deduplicate clusters by converting the list of sets to a set of frozensets\n",
    "    unique_clusters = set(frozenset(cluster) for cluster in clusters)\n",
    "    \n",
    "    # If you need the unique clusters back in list of lists format:\n",
    "    unique_clusters_list = [list(cluster) for cluster in unique_clusters]\n",
    "    \n",
    "    near_duplicates_idx_to_drop = []\n",
    "    \n",
    "    for cluster in unique_clusters_list:\n",
    "        # Calculate the number of rows to drop, ensuring at least one datapoint remains\n",
    "        n_drop = max(math.ceil(len(cluster) * drop_near_duplicate), 1)  # Drop at least k% or 1 row\n",
    "        if len(cluster) > n_drop:  # Ensure we keep at least one datapoint\n",
    "            # Randomly select datapoints to drop\n",
    "            drops = random.sample(cluster, n_drop)\n",
    "        else:\n",
    "            # If the cluster is too small, adjust the number to keep at least one datapoint\n",
    "            drops = random.sample(cluster, len(cluster) - 1)  # Keep at least one\n",
    "        near_duplicates_idx_to_drop.extend(drops)\n",
    "    \n",
    "    # Determine the specific indices to drop\n",
    "    label_issues_idx_to_drop = label_issues_idx[:num_label_issues_to_drop]\n",
    "    outliers_idx_to_drop = outliers_idx[:num_outliers_to_drop]\n",
    "    \n",
    "    # Combine the indices to drop\n",
    "    idx_to_drop = list(set(label_issues_idx_to_drop + near_duplicates_idx_to_drop + outliers_idx_to_drop))\n",
    "    \n",
    "    # Drop the rows from the training data\n",
    "    train_features_cleaned = train_features.drop(idx_to_drop).reset_index(drop=True)\n",
    "    train_labels_cleaned = train_labels.drop(idx_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    return train_features_cleaned, train_labels_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f5aa2883-d20d-481f-a012-fcc7ff8e3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the parameter grid as lists of possible values\n",
    "param_grid = {\n",
    "    'drop_label_issue': [0.4, 0.5, 0.6],\n",
    "    'drop_near_duplicate': [0.1, 0.2, 0.3],\n",
    "    'drop_outlier': [0.4, 0.5, 0.6],\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_combinations = list(product(param_grid['drop_label_issue'], param_grid['drop_near_duplicate'], param_grid['drop_outlier']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ce1c0ada-88b1-4654-b43f-3c0b59002979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'drop_label_issue': 0.6, 'drop_near_duplicate': 0.1, 'drop_outlier': 0.6}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for drop_label_issue, drop_near_duplicate, drop_outlier in param_combinations:\n",
    "    # Preprocess the data for the current combination of parameters\n",
    "    train_features_preprocessed, train_labels_preprocessed = preprocess_data(\n",
    "        train_features_v2, train_labels_v2, label_issues, near_duplicates, outliers,\n",
    "        drop_label_issue, drop_near_duplicate, drop_outlier)\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    model = XGBClassifier(tree_method=\"hist\", enable_categorical=True)\n",
    "    model.fit(train_features_preprocessed, train_labels_preprocessed)\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    # Update the best score and parameters if the current model is better\n",
    "    if accuracy > best_score:\n",
    "        best_score = accuracy\n",
    "        best_params = {'drop_label_issue': drop_label_issue, 'drop_near_duplicate': drop_near_duplicate, 'drop_outlier': drop_outlier}\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3f572acf-31c3-4874-9100-451796e35b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to clean training data based on the optimal combinations of hyperparameters to clean our data, measured on clean test data: 82.1%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy of model fit to clean training data based on the optimal combinations of hyperparameters to clean our data, measured on clean test data: {round(best_score*100,1)}%\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mturk-env",
   "language": "python",
   "name": "mturk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
